import openai
import pyttsx3

# Ø¥Ø¹Ø¯Ø§Ø¯ Ù…ÙØªØ§Ø­ OpenAI (Ø§Ø³ØªØ¨Ø¯Ù„ÙŠ Ø§Ù„Ù…ÙØªØ§Ø­ Ø¨Ù…ÙØªØ§Ø­Ùƒ Ø§Ù„ÙØ¹Ù‘Ø§Ù„)
client = openai.OpenAI(api_key=" sk-")

# Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ Ø§Ù„Ù…Ø³Ø¬Ù„
audio_path = "my_recording.wav"

# ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Whisper
with open(audio_path, "rb") as audio_file:
    transcription = client.audio.transcriptions.create(
        model="whisper-1",
        file=audio_file
    )

# Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø­ÙˆÙ„ Ù…Ù† Ø§Ù„ØµÙˆØª
user_text = transcription.text
print("ğŸ¤ Transcribed Text:")
print(user_text)

# ØªÙˆÙ„ÙŠØ¯ Ø±Ø¯ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… GPT
response = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "user", "content": user_text}
    ]
)

# Ø§Ù„Ø±Ø¯ Ø§Ù„Ù†ØµÙŠ Ù…Ù† GPT
reply = response.choices[0].message.content
print("ğŸ¤– GPT Reply:")
print(reply)

# ØªØ´ØºÙŠÙ„ Ø§Ù„Ø±Ø¯ Ø¨ØµÙˆØª
engine = pyttsx3.init()
engine.say(reply)
engine.runAndWait()
